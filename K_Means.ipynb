{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "df = pd.read_csv(\"C:/Users/Akash Iyer/OneDrive/Desktop/IoT/Project/test2.csv\") \n",
    "df \n",
    "#Dropping NaN values \n",
    "df=df.dropna() \n",
    "df.head() \n",
    "#Dropping outliers rows of each column \n",
    "micro1_mean=df[\"0.3um\"].mean() \n",
    "micro1_std=df[\"0.3um\"].std() \n",
    "micro2_mean=df[\"0.5um\"].mean() \n",
    "micro2_std=df[\"0.5um\"].std() \n",
    "micro3_mean=df[\"1um\"].mean() \n",
    "micro3_std=df[\"1um\"].std() \n",
    "micro4_mean=df[\"2.5um\"].mean() \n",
    "micro4_std=df[\"2.5um\"].std() \n",
    "micro5_mean=df[\"5um\"].mean() \n",
    "micro5_std=df[\"5um\"].std() \n",
    "micro6_mean=df[\"10um\"].mean() \n",
    "micro6_std=df[\"10um\"].std() \n",
    "pm1_mean=df[\"PM1.0\"].mean() \n",
    "pm1_std=df[\"PM1.0\"].std() \n",
    "pm2_mean=df[\"PM2.5\"].mean() \n",
    "pm2_std=df[\"PM2.5\"].std() \n",
    "pm3_mean=df[\"PM10\"].mean() \n",
    "pm3_std=df[\"PM10\"].std() \n",
    "df_cleaned=df[(df[\"0.3um\"]>=(micro1_mean\n",
    "3*micro1_std))&(df[\"0.3um\"]<=(micro1_mean+3*micro1_std))] \n",
    "df_cleaned=df_cleaned[(df_cleaned[\"0.5um\"]>=(micro2_mean\n",
    "3*micro2_std))&(df_cleaned[\"0.5um\"]<=(micro2_mean+3*micro2_std))] \n",
    "df_cleaned=df_cleaned[(df_cleaned[\"1um\"]>=(micro3_mean\n",
    "3*micro3_std))&(df_cleaned[\"1um\"]<=(micro3_mean+3*micro3_std))] \n",
    "df_cleaned=df_cleaned[(df_cleaned[\"2.5um\"]>=(micro4_mean\n",
    "3*micro4_std))&(df_cleaned[\"2.5um\"]<=(micro4_mean+3*micro4_std))] \n",
    "df_cleaned=df_cleaned[(df_cleaned[\"5um\"]>=(micro5_mean\n",
    "3*micro5_std))&(df_cleaned[\"5um\"]<=(micro5_mean+3*micro5_std))] \n",
    "df_cleaned=df_cleaned[(df_cleaned[\"10um\"]>=(micro6_mean\n",
    "3*micro6_std))&(df_cleaned[\"10um\"]<=(micro6_mean+3*micro6_std))] \n",
    "df_cleaned=df_cleaned[(df_cleaned[\"PM1.0\"]>=(pm1_mean\n",
    "3*pm1_std))&(df_cleaned[\"PM1.0\"]<=(pm1_mean+3*pm1_std))] \n",
    "df_cleaned=df_cleaned[(df_cleaned[\"PM2.5\"]>=(pm2_mean\n",
    "3*pm2_std))&(df_cleaned[\"PM2.5\"]<=(pm2_mean+3*pm2_std))] \n",
    "df_cleaned=df_cleaned[(df_cleaned[\"PM10\"]>=(pm3_mean\n",
    "3*pm3_std))&(df_cleaned[\"PM10\"]<=(pm3_mean+3*pm3_std))] \n",
    "df_cleaned.head() \n",
    "df1=df_cleaned.copy() \n",
    "df1['Date Index']=np.arange(len(df1.index)) \n",
    "df1.head() \n",
    "# Training data \n",
    "X1 = df1[['Date Index','0.3um']] \n",
    "X2 = df1[['Date Index','0.5um']] \n",
    "X3 = df1[['Date Index','1um']] \n",
    "X4 = df1[['Date Index','2.5um']] \n",
    "X5 = df1[['Date Index','5um']] \n",
    "X6 = df1[['Date Index','10um']] \n",
    "X7 = df1[['Date Index','PM1.0']] \n",
    "X8 = df1[['Date Index','PM2.5']] \n",
    "X9 = df1[['Date Index','PM10']] \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X1) \n",
    "scaled_data1 = scaler.transform(X1) \n",
    "scaled_data \n",
    "scaler.fit(X2) \n",
    "scaled_data2 = scaler.transform(X2) \n",
    "scaled_data2 \n",
    "scaler.fit(X3) \n",
    "scaled_data3 = scaler.transform(X3) \n",
    "scaled_data3 \n",
    "scaler.fit(X4) \n",
    "scaled_data4 = scaler.transform(X4) \n",
    "scaled_data4 \n",
    "scaler.fit(X5) \n",
    "scaled_data5 = scaler.transform(X5) \n",
    "scaled_data5 \n",
    "scaler.fit(X6) \n",
    "scaled_data6 = scaler.transform(X6) \n",
    "scaled_data6 \n",
    "scaler.fit(X7) \n",
    "scaled_data7 = scaler.transform(X7) \n",
    "scaled_data7 \n",
    "scaler.fit(X8) \n",
    "scaled_data8 = scaler.transform(X8) \n",
    "scaled_data8 \n",
    "scaler.fit(X9) \n",
    "scaled_data9 = scaler.transform(X9) \n",
    "scaled_data9 \n",
    "from sklearn.cluster import KMeans \n",
    "import matplotlib.pyplot as plt \n",
    "kmeans1 = KMeans(n_clusters=4, random_state=0,init='k-means++',n_init=10)  \n",
    "kmeans1.fit(scaled_data1) \n",
    "df1[\"clusters_0.3\"]=kmeans1.labels_ \n",
    "df1.head() \n",
    "kmeans2 = KMeans(n_clusters=4, random_state=0,init='k-means++',n_init=10)  \n",
    "kmeans2.fit(scaled_data2) \n",
    "df1[\"clusters_0.5\"]=kmeans2.labels_ \n",
    "df1.head() \n",
    "kmeans3 = KMeans(n_clusters=4, random_state=0,init='k-means++',n_init=10)  \n",
    "kmeans3.fit(scaled_data3) \n",
    "df1[\"clusters_1\"]=kmeans3.labels_ \n",
    "df1.head() \n",
    "kmeans4 = KMeans(n_clusters=4, random_state=0,init='k-means++',n_init=10)  \n",
    "kmeans4.fit(scaled_data4) \n",
    "df1[\"clusters_2.5\"]=kmeans4.labels_ \n",
    "df1.head() \n",
    "kmeans5 = KMeans(n_clusters=3, random_state=0,init='k-means++',n_init=10)  \n",
    "kmeans5.fit(scaled_data5) \n",
    "df1[\"clusters_5\"]=kmeans5.labels_ \n",
    "df1.head() \n",
    "kmeans6 = KMeans(n_clusters=2, random_state=0,init='k-means++',n_init=10)  \n",
    "kmeans6.fit(scaled_data6) \n",
    "df1[\"clusters_10\"]=kmeans6.labels_ \n",
    "df1.head() \n",
    "kmeans7 = KMeans(n_clusters=4, random_state=0,init='k-means++',n_init=10)  \n",
    "kmeans7.fit(scaled_data7) \n",
    "df1[\"clusters_PM1.0\"]=kmeans7.labels_ \n",
    "df1.head() \n",
    "kmeans8 = KMeans(n_clusters=4, random_state=0,init='k-means++',n_init=10)  \n",
    "kmeans8.fit(scaled_data8) \n",
    "df1[\"clusters_PM2.5\"]=kmeans8.labels_ \n",
    "df1.head() \n",
    "kmeans9 = KMeans(n_clusters=4, random_state=0,init='k-means++',n_init=10)  \n",
    "kmeans9.fit(scaled_data9) \n",
    "df1[\"clusters_PM10\"]=kmeans9.labels_ \n",
    "df1.head() \n",
    "plt.scatter(df1['Date Index'],df1['0.3um'],c=df1[\"clusters_0.3\"]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df1['Date Index'],df1['0.5um'],c=df1[\"clusters_0.5\"]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df1['Date Index'],df1['1um'],c=df1[\"clusters_1\"]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df1['Date Index'],df1['2.5um'],c=df1[\"clusters_2.5\"]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df1['Date Index'],df1['5um'],c=df1[\"clusters_5\"]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df1['Date Index'],df1['10um'],c=df1[\"clusters_10\"]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df1['Date Index'],df1['PM1.0'],c=df1[\"clusters_PM1.0\"]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df1['Date Index'],df1['PM2.5'],c=df1[\"clusters_PM2.5\"]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df1['Date Index'],df1['PM10'],c=df1[\"clusters_PM10\"]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
